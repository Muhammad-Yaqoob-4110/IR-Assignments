{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self):\n",
    "        self.index = {}\n",
    "        self.documents = {}\n",
    "        self.document_titles = {} \n",
    "        self.stopwords = set([\"the\", \"is\", \"in\", \"and\", \"to\", \"a\", \"of\", \"on\", \"with\", \"it\", \"for\", \"as\", \"by\", \"an\", \"can\", \"from\"])\n",
    "\n",
    "    def create_indexer(self, doc_id, title, text):\n",
    "        \"\"\"Add or update a document in the index.\"\"\"\n",
    "        # CASE FOLDING AND TOKENIZATION\n",
    "        tokens = self._tokenize(text)\n",
    "        if doc_id in self.documents:\n",
    "            self.remove_document(doc_id)\n",
    "\n",
    "        self.documents[doc_id] = text\n",
    "        self.document_titles[doc_id] = title\n",
    "\n",
    "        # CREATING INDEXER\n",
    "        for token in tokens:\n",
    "            if token not in self.index:\n",
    "                self.index[token] = {}\n",
    "            if doc_id not in self.index[token]:\n",
    "                self.index[token][doc_id] = 0\n",
    "            self.index[token][doc_id] += 1\n",
    "\n",
    "    def add_single_document(self, file_path):\n",
    "        \"\"\"Add a single document from a file.\"\"\"\n",
    "        # Pre processing\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            title = os.path.splitext(os.path.basename(file_path))[0]  # Extract title from file name\n",
    "            content = file.read()\n",
    "            doc_id = hash(file_path)  # Use a hash of the file path as a unique ID\n",
    "            # Indexer\n",
    "            self.create_indexer(doc_id, title, content)\n",
    "\n",
    "    def add_documents_from_directory(self, directory_path):\n",
    "        \"\"\"Adds all text files from a directory to the index.\"\"\"\n",
    "        for file_name in os.listdir(directory_path):\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                file_path = os.path.join(directory_path, file_name)\n",
    "                self.add_single_document(file_path)\n",
    "\n",
    "    def _case_folding(self, text):\n",
    "        \"\"\"Convert text to lowercase.\"\"\"\n",
    "        return text.lower()\n",
    "\n",
    "    def _tokenization(self, text):\n",
    "        \"\"\"Split text into words.\"\"\"\n",
    "        return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    def _remove_stopwords(self, words):\n",
    "        \"\"\"Remove stopwords from a list of words.\"\"\"\n",
    "        return [word for word in words if word not in self.stopwords]\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        \"\"\"Perform all steps: case folding, tokenization, and stopword removal.\"\"\"\n",
    "        lower_text = self._case_folding(text)\n",
    "        words = self._tokenization(lower_text)\n",
    "        return self._remove_stopwords(words)\n",
    "\n",
    "\n",
    "    def search(self, word):\n",
    "        \"\"\"Search for a word in the index.\"\"\"\n",
    "        word = word.lower()\n",
    "        if word in self.index:\n",
    "            results = self.index[word]\n",
    "            return {self.document_titles[doc_id]: count for doc_id, count in results.items()}\n",
    "        return {}\n",
    "\n",
    "    def remove_document(self, doc_id):\n",
    "        \"\"\"Remove a document from the index.\"\"\"\n",
    "        if doc_id in self.documents:\n",
    "            tokens = self._tokenize(self.documents[doc_id])\n",
    "            for token in tokens:\n",
    "                if token in self.index and doc_id in self.index[token]:\n",
    "                    del self.index[token][doc_id]\n",
    "                    if not self.index[token]:\n",
    "                        del self.index[token]\n",
    "            del self.documents[doc_id]\n",
    "            del self.document_titles[doc_id]\n",
    "    \n",
    "    def print_index(self):\n",
    "        \"\"\"Print the entire index in a meaningful way.\"\"\"\n",
    "        print(\"Final Index:\")\n",
    "        for word, doc_data in self.index.items():\n",
    "            doc_info = {self.document_titles[doc_id]: count for doc_id, count in doc_data.items()}\n",
    "            print(f\"{word}: {doc_info}\")\n",
    "\n",
    "    def search_document_by_title(self, title):\n",
    "        \"\"\"Search and return the content of a document by its title.\"\"\"\n",
    "        for doc_id, doc_title in self.document_titles.items():\n",
    "            if doc_title.lower() == title.lower():\n",
    "                return self.documents[doc_id]\n",
    "        return f\"Document with title '{title}' not found.\"\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = InvertedIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for 'fox': {'Nature and Wildlife': 1, 'Space Exploration': 1}\n",
      "Search results for 'python': {'Technology and Programming': 1}\n",
      "Search results for 'exercise': {'Health and Fitness': 2}\n",
      "Search results for 'adventure': {'Travel and Adventure': 1}\n"
     ]
    }
   ],
   "source": [
    "# Add all documents from a specified directory\n",
    "directory_path = \"./Documents_01\"\n",
    "index.add_documents_from_directory(directory_path)\n",
    "\n",
    "# Search for words\n",
    "print(\"Search results for 'fox':\", index.search(\"fox\"))\n",
    "print(\"Search results for 'python':\", index.search(\"python\"))\n",
    "print(\"Search results for 'exercise':\", index.search(\"exercise\"))\n",
    "print(\"Search results for 'adventure':\", index.search(\"adventure\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for 'fox': {'Nature and Wildlife': 1, 'Space Exploration': 1}\n",
      "Search results for 'space': {'Space Exploration': 1}\n"
     ]
    }
   ],
   "source": [
    "# Add a newly added document\n",
    "index.add_single_document(\"./Documents_01/Space Exploration.txt\")\n",
    "print(\"Search results for 'fox':\", index.search(\"fox\"))\n",
    "print(\"Search results for 'space':\", index.search(\"space\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Index:\n",
      "Final Index:\n",
      "healthy: {'Health and Fitness': 1}\n",
      "lifestyle: {'Health and Fitness': 1}\n",
      "includes: {'Health and Fitness': 1}\n",
      "regular: {'Health and Fitness': 1}\n",
      "exercise: {'Health and Fitness': 2}\n",
      "balanced: {'Health and Fitness': 1}\n",
      "diet: {'Health and Fitness': 1}\n",
      "sufficient: {'Health and Fitness': 1}\n",
      "sleep: {'Health and Fitness': 1}\n",
      "help: {'Health and Fitness': 1}\n",
      "reduce: {'Health and Fitness': 1}\n",
      "stress: {'Health and Fitness': 1}\n",
      "improve: {'Health and Fitness': 1}\n",
      "overall: {'Health and Fitness': 1}\n",
      "well: {'Health and Fitness': 1}\n",
      "being: {'Health and Fitness': 1}\n",
      "quick: {'Nature and Wildlife': 1}\n",
      "brown: {'Nature and Wildlife': 1}\n",
      "fox: {'Nature and Wildlife': 1, 'Space Exploration': 1}\n",
      "jumps: {'Nature and Wildlife': 1}\n",
      "over: {'Nature and Wildlife': 1}\n",
      "lazy: {'Nature and Wildlife': 1}\n",
      "dog: {'Nature and Wildlife': 1}\n",
      "forest: {'Nature and Wildlife': 1}\n",
      "full: {'Nature and Wildlife': 1}\n",
      "wonderful: {'Nature and Wildlife': 1}\n",
      "creatures: {'Nature and Wildlife': 1}\n",
      "including: {'Nature and Wildlife': 1}\n",
      "foxes: {'Nature and Wildlife': 1}\n",
      "deer: {'Nature and Wildlife': 1}\n",
      "space: {'Space Exploration': 1}\n",
      "exploration: {'Space Exploration': 1}\n",
      "has: {'Space Exploration': 1}\n",
      "always: {'Space Exploration': 1}\n",
      "fascinated: {'Space Exploration': 1}\n",
      "humanity: {'Space Exploration': 1}\n",
      "moon: {'Space Exploration': 1}\n",
      "landings: {'Space Exploration': 1}\n",
      "mars: {'Space Exploration': 1}\n",
      "rovers: {'Space Exploration': 1}\n",
      "advancements: {'Space Exploration': 1}\n",
      "technology: {'Space Exploration': 1}\n",
      "have: {'Space Exploration': 1}\n",
      "made: {'Space Exploration': 1}\n",
      "possible: {'Space Exploration': 1}\n",
      "explore: {'Space Exploration': 1}\n",
      "universe: {'Space Exploration': 1}\n",
      "satellites: {'Space Exploration': 1}\n",
      "telescopes: {'Space Exploration': 1}\n",
      "continue: {'Space Exploration': 1}\n",
      "provide: {'Space Exploration': 1}\n",
      "valuable: {'Space Exploration': 1}\n",
      "insights: {'Space Exploration': 1}\n",
      "about: {'Space Exploration': 1}\n",
      "our: {'Space Exploration': 1}\n",
      "galaxy: {'Space Exploration': 1}\n",
      "beyond: {'Space Exploration': 1}\n",
      "python: {'Technology and Programming': 1}\n",
      "versatile: {'Technology and Programming': 1}\n",
      "programming: {'Technology and Programming': 1}\n",
      "language: {'Technology and Programming': 1}\n",
      "that: {'Technology and Programming': 1}\n",
      "widely: {'Technology and Programming': 1}\n",
      "used: {'Technology and Programming': 1}\n",
      "web: {'Technology and Programming': 1}\n",
      "development: {'Technology and Programming': 1}\n",
      "data: {'Technology and Programming': 1}\n",
      "analysis: {'Technology and Programming': 1}\n",
      "artificial: {'Technology and Programming': 1}\n",
      "intelligence: {'Technology and Programming': 1}\n",
      "loved: {'Technology and Programming': 1}\n",
      "developers: {'Technology and Programming': 1}\n",
      "its: {'Technology and Programming': 1}\n",
      "simplicity: {'Technology and Programming': 1}\n",
      "power: {'Technology and Programming': 1}\n",
      "exploring: {'Travel and Adventure': 1}\n",
      "new: {'Travel and Adventure': 1}\n",
      "destinations: {'Travel and Adventure': 1}\n",
      "exciting: {'Travel and Adventure': 1}\n",
      "adventure: {'Travel and Adventure': 1}\n",
      "mountains: {'Travel and Adventure': 1}\n",
      "forests: {'Travel and Adventure': 1}\n",
      "oceans: {'Travel and Adventure': 1}\n",
      "offer: {'Travel and Adventure': 1}\n",
      "incredible: {'Travel and Adventure': 1}\n",
      "opportunities: {'Travel and Adventure': 1}\n",
      "hiking: {'Travel and Adventure': 1}\n",
      "wildlife: {'Travel and Adventure': 1}\n",
      "observation: {'Travel and Adventure': 1}\n",
      "relaxation: {'Travel and Adventure': 1}\n"
     ]
    }
   ],
   "source": [
    "# Print the entire indexer\n",
    "print(\"\\nFinal Index:\")\n",
    "index.print_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of 'Nature and Wildlife':\n",
      "The quick brown fox jumps over the lazy dog. The forest is full of wonderful creatures, including foxes and deer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for a document by title\n",
    "doc_title = \"Nature and Wildlife\"  # Replace with the title you want to search\n",
    "document_content = index.search_document_by_title(doc_title)\n",
    "print(f\"Content of '{doc_title}':\\n{document_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
