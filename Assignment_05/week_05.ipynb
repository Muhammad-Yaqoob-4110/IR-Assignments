{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Extended IR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Representation\n",
    "I've first represented the documents as binary vectors, where each term's presence is indicated by 1 and absence by 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Query Processing\n",
    "I've implemented basic query processing that supports AND, OR, and NOT. The query processor will take a Boolean query, parse it, and apply the operations on the term-document matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Algorithm\n",
    "The ranking algorithm will rank documents based on the number of matching terms. For Boolean expressions, the rank will be binary (either the document matches or it doesnâ€™t). For more complex queries, partial satisfaction can be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['algorithm', 'dynamic', 'graph', 'optimization', 'programming', 'sorting', 'theory']\n",
      "Document 1: [1, 0, 0, 1, 0, 1, 0]\n",
      "Document 2: [1, 1, 1, 0, 0, 0, 1]\n",
      "Document 3: [0, 1, 0, 1, 1, 0, 0]\n",
      "\n",
      "Query: algorithm AND optimization NOT dynamic\n",
      "Ranked Documents:\n",
      "Document 1: algorithm optimization sorting\n",
      "\n",
      "Query: optimization OR dynamic\n",
      "Ranked Documents:\n",
      "Document 1: algorithm optimization sorting\n",
      "Document 2: algorithm dynamic graph theory\n",
      "Document 3: optimization dynamic programming\n",
      "\n",
      "Query: algorithm NOT graph\n",
      "Ranked Documents:\n",
      "Document 1: algorithm optimization sorting\n",
      "Document 3: optimization dynamic programming\n",
      "\n",
      "Query: algorithm NOT graph AND optimization OR dynamic\n",
      "Ranked Documents:\n",
      "Document 1: algorithm optimization sorting\n",
      "Document 2: algorithm dynamic graph theory\n",
      "Document 3: optimization dynamic programming\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Set, Tuple\n",
    "\n",
    "class BooleanExtendedIRModel:\n",
    "    def __init__(self, documents: List[str]):\n",
    "        \"\"\"\n",
    "        Initialize the Boolean Extended IR Model\n",
    "        \n",
    "        Args:\n",
    "            documents (List[str]): Collection of input documents\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "        self.vocab: Set[str] = set()\n",
    "        self.processed_docs: List[List[str]] = []\n",
    "        self.term_doc_matrix: List[List[int]] = []\n",
    "        \n",
    "        # Term weight matrix (optional enhancement)\n",
    "        self.term_weights: dict = {}\n",
    "        \n",
    "        # Preprocessing\n",
    "        self.preprocess_documents()\n",
    "    \n",
    "    def preprocess_documents(self) -> None:\n",
    "        \"\"\"\n",
    "        Preprocess documents into vocabulary and processed documents\n",
    "        \"\"\"\n",
    "        \n",
    "        for doc in self.documents:\n",
    "            # Tokenize and clean terms\n",
    "            terms = self._clean_and_tokenize(doc)\n",
    "            self.vocab.update(terms)\n",
    "            self.processed_docs.append(terms)\n",
    "        \n",
    "        # Convert vocab to sorted list for consistent indexing\n",
    "        self.vocab = sorted(list(self.vocab))\n",
    "\n",
    "        print(\"Vocab:\", self.vocab)\n",
    "        \n",
    "        # Create term document matrix\n",
    "        self.term_doc_matrix = self.create_term_document_matrix()\n",
    "\n",
    "        for i, row in enumerate(self.term_doc_matrix):\n",
    "            print(f\"Document {i + 1}: {row}\")\n",
    "        \n",
    "        # Initialize term weights (optional)\n",
    "        self._initialize_term_weights()\n",
    "    \n",
    "    def _clean_and_tokenize(self, document: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Clean and tokenize a document\n",
    "        \n",
    "        Args:\n",
    "            document (str): Input document string\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: Cleaned and tokenized terms\n",
    "        \"\"\"\n",
    "        # Basic cleaning: lowercase, split\n",
    "        return document.lower().split()\n",
    "    \n",
    "    def _initialize_term_weights(self) -> None:\n",
    "        \"\"\"\n",
    "        Initialize term weights based on term frequency\n",
    "        \"\"\"\n",
    "        for term in self.vocab:\n",
    "            # Simple weight calculation based on document frequency\n",
    "            doc_frequency = sum(self.get_term_vector(term))\n",
    "            self.term_weights[term] = 1 + (doc_frequency / len(self.documents))\n",
    "    \n",
    "    def create_term_document_matrix(self) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Create binary term-document matrix\n",
    "        \n",
    "        Returns:\n",
    "            List[List[int]]: Binary matrix representing term presence\n",
    "        \"\"\"\n",
    "        matrix = []\n",
    "        for doc in self.processed_docs:\n",
    "            vector = [1 if term in doc else 0 for term in self.vocab]\n",
    "            matrix.append(vector)\n",
    "        \n",
    "        return matrix\n",
    "    \n",
    "    def get_term_vector(self, term: str) -> List[int]:\n",
    "        \"\"\"\n",
    "        Get binary vector for a given term\n",
    "        \n",
    "        Args:\n",
    "            term (str): Term to retrieve vector for\n",
    "        \n",
    "        Returns:\n",
    "            List[int]: Binary vector representing term presence\n",
    "        \"\"\"\n",
    "        if term not in self.vocab:\n",
    "            # logger.warning(f\"Term '{term}' not in vocabulary\")\n",
    "            return [0] * len(self.documents)\n",
    "        \n",
    "        index = self.vocab.index(term)\n",
    "        return [doc[index] for doc in self.term_doc_matrix]\n",
    "    \n",
    "    def and_operation(self, vec1: List[int], vec2: List[int]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Perform AND operation on two vectors\n",
    "        \n",
    "        Args:\n",
    "            vec1 (List[int]): First binary vector\n",
    "            vec2 (List[int]): Second binary vector\n",
    "        \n",
    "        Returns:\n",
    "            List[int]: Resulting binary vector\n",
    "        \"\"\"\n",
    "        return [x & y for x, y in zip(vec1, vec2)]\n",
    "    \n",
    "    def or_operation(self, vec1: List[int], vec2: List[int]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Perform OR operation on two vectors\n",
    "        \n",
    "        Args:\n",
    "            vec1 (List[int]): First binary vector\n",
    "            vec2 (List[int]): Second binary vector\n",
    "        \n",
    "        Returns:\n",
    "            List[int]: Resulting binary vector\n",
    "        \"\"\"\n",
    "        return [x | y for x, y in zip(vec1, vec2)]\n",
    "    \n",
    "    def not_operation(self, vec: List[int]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Perform NOT operation on a vector\n",
    "        \n",
    "        Args:\n",
    "            vec (List[int]): Input binary vector\n",
    "        \n",
    "        Returns:\n",
    "            List[int]: Inverted binary vector\n",
    "        \"\"\"\n",
    "        return [1 - x for x in vec]\n",
    "    \n",
    "    def process_query(self, query: str) -> List[int]:\n",
    "        \"\"\"\n",
    "        Process complex Boolean query\n",
    "        \n",
    "        Args:\n",
    "            query (str): Boolean query string\n",
    "        \n",
    "        Returns:\n",
    "            List[int]: Result vector indicating matching documents\n",
    "        \"\"\"\n",
    "        \n",
    "        terms = query.split()\n",
    "        result_vector = []\n",
    "\n",
    "        i = 0\n",
    "        while i < len(terms):\n",
    "            term = terms[i]\n",
    "            \n",
    "            if term == \"AND\":\n",
    "                next_term = terms[i + 1]\n",
    "                result_vector = self.and_operation(result_vector, self.get_term_vector(next_term))\n",
    "                i += 2\n",
    "            elif term == \"OR\":\n",
    "                next_term = terms[i + 1]\n",
    "                result_vector = self.or_operation(result_vector, self.get_term_vector(next_term))\n",
    "                i += 2\n",
    "            elif term == \"NOT\":\n",
    "                next_term = terms[i + 1]\n",
    "                result_vector = self.not_operation(self.get_term_vector(next_term))\n",
    "                i += 2\n",
    "            else:\n",
    "                result_vector = self.get_term_vector(term)\n",
    "                i += 1\n",
    "\n",
    "        return result_vector\n",
    "    \n",
    "    def rank_documents(self, result_vector: List[int]) -> List[Tuple[int, str]]:\n",
    "        \"\"\"\n",
    "        Rank documents based on result vector\n",
    "        \n",
    "        Args:\n",
    "            result_vector (List[int]): Binary vector of matching documents\n",
    "        \n",
    "        Returns:\n",
    "            List[Tuple[int, str]]: List of ranked documents with indices\n",
    "        \"\"\"\n",
    "        ranked_docs = [\n",
    "            (i, self.documents[i]) \n",
    "            for i in range(len(result_vector)) \n",
    "            if result_vector[i] == 1\n",
    "        ]\n",
    "        return ranked_docs\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Sample documents\n",
    "    documents = [\n",
    "        \"algorithm optimization sorting\",\n",
    "        \"algorithm dynamic graph theory\",\n",
    "        \"optimization dynamic programming\"\n",
    "    ]\n",
    "    \n",
    "    # Create Boolean Extended IR Model instance\n",
    "    ir_model = BooleanExtendedIRModel(documents)\n",
    "    \n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"algorithm AND optimization NOT dynamic\",\n",
    "        \"optimization OR dynamic\",\n",
    "        \"algorithm NOT graph\",\n",
    "        \"algorithm NOT graph AND optimization OR dynamic\",\n",
    "    ]\n",
    "    \n",
    "    # Process and rank documents for each query\n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        \n",
    "        result_vector = ir_model.process_query(query)\n",
    "        ranked_docs = ir_model.rank_documents(result_vector)\n",
    "        \n",
    "        print(\"Ranked Documents:\")\n",
    "        for doc in ranked_docs:\n",
    "            print(f\"Document {doc[0] + 1}: {doc[1]}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
