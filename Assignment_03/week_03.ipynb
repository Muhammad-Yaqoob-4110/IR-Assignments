{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Independence Model (BIM) for probabilistic information retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the BIM Model\n",
    "I have choosen the Binary Independence Model (BIM) as the probabilistic retrieval model for your information retrieval task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "I need to tokenize, stem, and remove stop words from both the documents and the query. Here is the function for the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Tokenize\n",
    "    tokens = text.lower().split()\n",
    "    # Remove stop words\n",
    "    stop_words = {'the', 'is', 'at', 'of', 'on', 'and', 'a', 'to'}\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Weighting\n",
    "For each document and the query, create a binary vector where each term is marked as 1 if present and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_vector(terms, vocab):\n",
    "    vector = [1 if term in terms else 0 for term in vocab]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_weighting(documents):\n",
    "    # Preprocess documents and build vocabulary\n",
    "    processed_docs = [preprocess(doc) for doc in documents]\n",
    "    vocab = sorted(set([term for doc in processed_docs for term in doc]))  # Unique terms in all documents\n",
    "    \n",
    "    # Create binary vectors for each document\n",
    "    doc_vectors = [create_binary_vector(doc, vocab) for doc in processed_docs]\n",
    "    return doc_vectors, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Representation\n",
    "Convert the user’s query into a binary vector using the vocabulary (terms across all documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_representation(query, vocab):\n",
    "    query_terms = preprocess(query)\n",
    "    return create_binary_vector(query_terms, vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Scoring\n",
    "The `scipy.spatial.distance` module includes a function called dice that computes the `Dice dissimilarity` between two boolean 1-D arrays. We can convert this dissimilarity to similarity by subtracting it from 1.\n",
    "\n",
    "[dice — SciPy v1.14.1 Manual. (n.d.). https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.dice.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.dice.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import dice\n",
    "\n",
    "def calculate_dice_coefficient(query_vector, doc_vector):\n",
    "    return 1 - dice(query_vector, doc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking\n",
    "Rank the documents based on their Dice coefficient scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_documents(query_vector, doc_vectors):\n",
    "    scores = [(i, calculate_dice_coefficient(query_vector, doc_vec)) for i, doc_vec in enumerate(doc_vectors)]\n",
    "    ranked_docs = sorted(scores, key=lambda x: x[1], reverse=True)  # Higher Dice score means more similarity\n",
    "    return ranked_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Top-K Documents\n",
    "I have retrieved the top-K most similar documents. If user doesnt provide, i will return first five top documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k_documents(ranked_docs, K=5):\n",
    "    return ranked_docs[:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_independence_model(documents, query, K=5):\n",
    "    # Preprocess and generate term-weighted document vectors\n",
    "    doc_vectors, vocab = term_weighting(documents)\n",
    "    \n",
    "    # Generate query vector\n",
    "    query_vector = query_representation(query, vocab)\n",
    "    \n",
    "    # Rank documents based on Dice coefficient scores\n",
    "    ranked_docs = rank_documents(query_vector, doc_vectors)\n",
    "    \n",
    "    # Retrieve top K documents\n",
    "    top_k_docs = retrieve_top_k_documents(ranked_docs, K)\n",
    "    \n",
    "    return top_k_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presentation of Results\n",
    "I have presented the sorted documented based on ranking score along with document titles as an additional information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 2, Score: 66.67% \n",
      "Document ID: 0, Score: 44.44% \n",
      "Document ID: 1, Score: 0.0% \n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"Never jump over the lazy dog quickly\",\n",
    "    \"A fox is quick and a dog is lazy\",\n",
    "]\n",
    "\n",
    "query = \"quick fox\"\n",
    "\n",
    "top_k_results = binary_independence_model(documents, query, K=3)\n",
    "for doc_id, score in top_k_results:\n",
    "    print(f\"Document ID: {doc_id}, Score: {round(score * 100, 2)}% \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Overlapped List Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Link List Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linked List class\n",
    "class LinkList:\n",
    "\n",
    "    # Private Node class\n",
    "    class Node:\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "            self.next = None\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "    \n",
    "    # Method to add a new node to the end of the list\n",
    "    def append(self, data):\n",
    "        new_node = self.Node(data)\n",
    "        if not self.head:\n",
    "            self.head = new_node\n",
    "            return\n",
    "        last = self.head\n",
    "        while last.next:\n",
    "            last = last.next\n",
    "        last.next = new_node\n",
    "    \n",
    "    # Method to convert linked list to a set for set operations\n",
    "    def to_set(self):\n",
    "        elements = set()\n",
    "        current = self.head\n",
    "        while current:\n",
    "            elements.add(current.data)\n",
    "            current = current.next\n",
    "        return elements\n",
    "    \n",
    "    # Method to print the linked list\n",
    "    def display(self):\n",
    "        current = self.head\n",
    "        while current:\n",
    "            print(current.data, end=\" -> \")\n",
    "            current = current.next\n",
    "        print(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Terms of Interest\n",
    "I am intrested in \"machine learning\" and \"data visualization.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Documents per Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linked lists for each term\n",
    "docs_machine_learning = LinkList()\n",
    "docs_machine_learning.append(\"Introduction to machine learning and its applications.\")\n",
    "docs_machine_learning.append(\"Machine learning models and data science.\")\n",
    "docs_machine_learning.append(\"Combining machine learning and data visualization.\")\n",
    "\n",
    "docs_data_visualization = LinkList()\n",
    "docs_data_visualization.append(\"Data visualization techniques and tools.\")\n",
    "docs_data_visualization.append(\"Effective data visualization methods.\")\n",
    "docs_data_visualization.append(\"Combining machine learning and data visualization.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Lists for Non-Overlapping Results\n",
    "I have defined a linklist to set method within a LinkList class to use set operations to find the union of the two sets of documents. This will give us the non-overlapping set of documents containing either of the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = docs_machine_learning.to_set()\n",
    "set2 = docs_data_visualization.to_set()\n",
    "non_overlap_set = set1.union(set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Combining machine learning and data visualization.',\n",
       " 'Data visualization techniques and tools.',\n",
       " 'Effective data visualization methods.',\n",
       " 'Introduction to machine learning and its applications.',\n",
       " 'Machine learning models and data science.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_overlap_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Nodes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Graph Data Structure\n",
    "I have used the dictionary with adjacency lists to represent the graph. Each node will be a key in a dictionary, and its value will be a list of connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph class to represent the network of documents and entities\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        # Initialize the graph with an empty adjacency list\n",
    "        self.graph = {}\n",
    "\n",
    "    # Add a node to the graph\n",
    "    def add_node(self, node):\n",
    "        if node not in self.graph:\n",
    "            self.graph[node] = []\n",
    "\n",
    "    # Add an edge between two nodes (undirected by default)\n",
    "    def add_edge(self, node1, node2):\n",
    "        if node1 in self.graph and node2 in self.graph:\n",
    "            self.graph[node1].append(node2)\n",
    "            self.graph[node2].append(node1)\n",
    "\n",
    "    # Retrieve connected nodes (documents) to the given node\n",
    "    def get_connected_nodes(self, node):\n",
    "        return self.graph.get(node, [])\n",
    "\n",
    "    # Display the graph (for debugging purposes)\n",
    "    def display(self):\n",
    "        for node in self.graph:\n",
    "            print(f\"{node}: {self.graph[node]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Nodes and Edges\n",
    "I have created nodes representing documents and add edges to represent relationships between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph instance\n",
    "document_graph = Graph()\n",
    "\n",
    "# Adding nodes (documents/entities)\n",
    "document_graph.add_node(\"NASA\")\n",
    "document_graph.add_node(\"astronauts\")\n",
    "document_graph.add_node(\"space missions\")\n",
    "document_graph.add_node(\"moon landing\")\n",
    "document_graph.add_node(\"Mars exploration\")\n",
    "document_graph.add_node(\"space exploration\")\n",
    "document_graph.add_node(\"space telescopes\")\n",
    "\n",
    "# Adding edges (relationships)\n",
    "document_graph.add_edge(\"NASA\", \"astronauts\")\n",
    "document_graph.add_edge(\"NASA\", \"space missions\")\n",
    "document_graph.add_edge(\"astronauts\", \"moon landing\")\n",
    "document_graph.add_edge(\"space missions\", \"Mars exploration\")\n",
    "document_graph.add_edge(\"NASA\", \"space telescopes\")\n",
    "document_graph.add_edge(\"space exploration\", \"NASA\")\n",
    "document_graph.add_edge(\"space exploration\", \"Mars exploration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display graph\n",
    "![Graph](./Documents_03/graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Proximal Nodes\n",
    "Suppose user is intrested in Space exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify proximal nodes based on interest\n",
    "proximal_nodes = [\"moon landing\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Network Relationships\n",
    "We'll traverse the graph to find all nodes connected to these proximal nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to explore network relationships and find connected documents\n",
    "def retrieve_documents(graph, proximal_nodes):\n",
    "    connected_documents = set()\n",
    "    for node in proximal_nodes:\n",
    "        # Retrieve all nodes directly connected to each proximal node\n",
    "        connected_nodes = graph.get_connected_nodes(node)\n",
    "        # Add the connected nodes to the result set\n",
    "        for connected_node in connected_nodes:\n",
    "            connected_documents.add(connected_node)\n",
    "    return connected_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Connected Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the connected documents\n",
    "relevant_documents = retrieve_documents(document_graph, proximal_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Present Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant documents based on proximal nodes:\n",
      "astronauts\n"
     ]
    }
   ],
   "source": [
    "# Present the results\n",
    "print(\"Relevant documents based on proximal nodes:\")\n",
    "for doc in relevant_documents:\n",
    "    print(doc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
